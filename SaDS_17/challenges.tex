This chapter lists examples of disasters and failures that serve as examples of what secure and dependable systems should avoid.

The lists are not complete and may be biased by whether
\begin{compactitem}
 \item I became aware of it and found it interesting enough
 \item the cause could be determined and was made public
\end{compactitem}
Feel free to edit these notes by adding important examples that I forgot when I compiled the lists.

All damage estimates are relative to the time of the event and not adjusted to inflation.

Note that for security problems, the size of the damage is naturally unknown because attacks will typically remain secret.
Only the cost of updating the systems can be estimated, which may or may not be indicative of the severity of the security problem.

\section{General Aspects}

\highlightframe{
State-of-the-art software and hardware systems simply are not safe, secure, and dependable.

Moreover, we do not understand very well yet how to make them so.
}

This is different from many other areas such as mechanical or chemical engineering.
While these occasionally cause disasters, these can usually be traced back to human error, foul play, or negligent or intentional violation of regulations.
Such disasters usually result in criminal proceedings, civil litigation, or revision or extension of regulations.
% what engineers know and how they know it

The situation is very different for computer systems.
There is no general methodology for designing and operating computer systems well that can be easily described, taught, or codified.

The situation will hopefully improve over the course of the 21st century.
The problem has been recognized decades ago, and many companies and researchers are working on it.
They approach from very different directions with different goals and different methodologies.

\highlightframe{
This has resulted in a wide and diverse variety of not coherently connected methods with varying degrees of depth, maturity, cost, benefit, and practical adoption.
}

A typical effect is a trade-off along a spectrum of methods:
\begin{compactitem}
 \item cheap but weak methods on one end
 \item strong but expensive methods on the other end.
\end{compactitem}
Therefore, it is often necessary to choose a degree of safety assurance rather than actually guarantee safety.
This spectrum is so extreme that
\begin{compactitem}
 \item the majority of practical software development does not systematically ensure any kind of safety,
 \item the majority of theoretical solutions are neither ready nor affordable for practical use.
\end{compactitem}

Incidentally, this means that this course's subject matter is much less well-defined than that of other courses.%
\footnote{For example, the other two courses in this module almost design themselves because the subject matter is very well understood and standardized.}
That makes it particular difficult to design a syllabus for.
It will give a overview of the most important state-of-the-art methods.

\section{Major Disasters Caused by Programming Errors}

\paragraph{Mariner 1}
The 1962 rocket launch of Mariner 1 failed causing damage of around \$20 million.

The cause was a programming error, where a mathematical formula in the specification was misread.

Details: \url{https://en.wikipedia.org/wiki/Mariner_1}

\paragraph{Therac-25}
Between 1985 and 1987, the Therac-25 machine for medical radiation therapy caused death and/or serious injury in at least $6$ cases.
Patients received a radiation overdose because the high intensity energy beam was administered while using the protection meant for the low intensity beam.

The cause was that the hardware protection was discontinued relying exclusively on software to prevent a mismatch of beam and protection configuration.
But the software had always been buggy due to a systemic failures in the software engineering process including complex systems (code written in assembly, machine had its own OS), lack of software review, insufficient testing (overall system could not be tested), bad documentation (error codes were not documented), and bad user interface (critical safety errors could be manually overridden, thus effectively being warnings).

Details: \url{https://en.wikipedia.org/wiki/Therac-25}

\paragraph{Patriot Rounding Error}
In 1991 during the Gulf war, a US Patriot anti-missile battery failed to track an incoming Iraqi Scud missile resulting the death of 28 people.

The cause was a rounding error in the floating point computation used for analyzing the missile's path.
The software had to divide a large integer (number of $0.1s$ clock cycles since boot $100$ hours ago) by $10$ to obtain the time.
This was done using a floating-point multiplication by $0.1$---but $0.1$ is off by around $0.000000095$ when chopped to a $24$-bits binary float.
The resulting time was off by $0.3$ seconds, which combined with the high speed of Scud missile led to a serious miscalculation of the flight path.

Details: \url{http://www-users.math.umn.edu/~arnold/disasters/patriot.html}

\paragraph{Ariane 5}
In 1996, the first launch of an Ariane 5 rocket (overall development cost \$$7$ billion) failed, and the rocket had to be destructed after launch.
Both the primary and the backup system had shut down, each trying to transfer control to the other, after encountering the same behavior, which they interpreted as a hardware error.

The cause was an overflow exception in the alignment system caused by converting a $64$-bit float to a $16$-bit integer, which was not caught and resulted in the display of diagnostic data that the autopilot could not interpret.
The programmers were away of the problem but had falsely concluded that no conversion check was needed (and therefore omitted the check to speed up processing).
Their conclusion had been made based on Ariane 4 flight data that turned out to be inappropriate for Ariane 5.

The faulty component was not even needed for flight and was only kept active for a brief time after launch for convenience and in order to avoid changing a running system.

Details: \url{http://www-users.math.umn.edu/~arnold/disasters/ariane5rep.html}

\paragraph{Intel Pentium Bug}
In 1994, it was discovered that the Intel Pentium processor (at the time widely used in desktop computers) wrongly computed certain floating point divisions.
The cost of replacing the CPUs was estimated at about \$$400$ million.

The error occurred in about 1 in 9 billion divisions.
For example, $4195835.0/3145727.0$ yielded $1.333 739 068 902 037 589$ instead of $1.333 820 449 136 241 000$.

The cause was a bug in the design of the floating point unit's circuit.

\paragraph{Kerberos Random Number Generator}
From 1988 to 1996, the network authentification protocol Kerberos used a mis-designed random number generation algorithm.
The resulting keys were so predictable that brute force attacks became trivial although it is unclear if the bug was ever exploited.

The cause was the lack of a truly random seed value for the algorithm.
Moreover, the error persisted across attempted fixes because of process failures (code hard to read, programmers had moved on to next version).

Detail: \url{http://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=2331&context=cstech}

\paragraph{USS Yorktown}
In 1997, critical navigation and weapons hardware on the USS Yorktown was paralyzed at sea for $3$ hours while rebooting machines.

The cause was a blank field in a database that was interpreted as $0$ leading to a division-by-zero.
Special floating point values such as infinity or NaN were not used resulting in an exception.
The exception was handled by neither the software nor the operating systems (Windows NT) thus crashing both.

Details: \url{http://www.cs.berkeley.edu/~wkahan/Boulder.pdf}

\paragraph{Mars Climate Orbiter}
In 1998 the Mars Climate Orbiter was lost causing damage of around \$$300$ million after software had calculated a false trajectory when updating the position of the spacecraft.

The cause was that two components by different manufacturers exchanged physical quantities as plain numbers (i.e., without units).
One component assumed customary units (pound seconds) whereas the other assumed SI units (Newton seconds).
The first component was in violation of the specification of the interface.

\paragraph{Year 2000 and 2038 Problems}
Leading to the year 2000, about \$$300$ billion were spent worldwide to update outdated software that was unable to handle dates with a year of $2000$ or higher.

The cause was that much software was used far beyond the originally envisioned lifetime.
At programming time, especially at times when memory was still scarce, it made sense to use only two digits for the year in a date.
That assumption became flawed when dates over $2000$ had to be handled.

A related problem is expected in the year 2038.
At that point the number of seconds since 1970-01-01, which is the dominant way of storing time on Unix, will exceed the capacity of a $32$-bit integer.
While application software is expected to be updated by then anyway, modern embedded systems may or may not still be in use.

\paragraph{Los Angeles Airport Network Outage}
In 2007, LA airport was partially blocked for $10$ due to a network outage that prevented passenger processing.
About 17,000 passengers were affected.

The cause was a single network card malfunction that flooded the network and propagated through the local area network.

Details: \url{https://www.oig.dhs.gov/assets/Mgmt/OIGr_08-58_May08.pdf}

\paragraph{Debian OpenSSL Random Number Generator}
From 2006 to 2008 Debian's variant of OpenSSL used a flawed random number generator.
This made the generated keys easily predictable and thus compromised.
It is unclear whether this was exploited.

The cause was that two values were used to obtain random input: the process ID and an uninitialized memory field.
Uninitialized memory should never be used but is sometimes used as a convenient way to cheaply obtain a random number in a low-level programming language like C.
The respective line of code had no immediately obvious purpose because it was not commented.
Therefore, it was removed by one contributor after code analysis tools had detected the use of uninitialized memory and flagged it as a potential bug.

Detail: \url{https://github.com/g0tmi1k/debian-ssh}

\paragraph{Knight Capital Trading Software}
In 2012, high-frequency trading company Knight Capital lost about \$$10$ million per minute for 45 minutes trading on the New York Stock Exchange.

The cause was an undisclosed bug in their automatic trading software.
% http://www.bbc.com/news/magazine-19214294

\paragraph{Heartbleed}
From 2012 to 2014, the OpenSSL library was susceptible to an attack that allowed remotely reading out sections of raw physical memory.
The affected sections were random but repeated attacks could piece together large parts of the memory.
The compromised memory sections could include arbitrary critical data such as passwords or encryption keys.
OpenSSL was used not only by many desktop and server applications but also in portable and embedded devices running Linux.
The upgrade costs are very hard to estimate but were put at multiple \$$100$ millions by some experts.

The cause was a bug in the Heartbeat component, which allowed sending a message to the server, which the server echoed back to test if the connection is alive.
The server code did not check whether the given message length $l$ was actually the length of the message $m$.
Instead, it always returned $l$ bytes starting from the memory address of $m$ even if $l$ was larger than the length of $m$.
This was possible because the used low-level programming language (C) let the programmers store $m$ in a memory buffer and then over-read from that buffer.
Moreover, their C code is so hard to read that it is impossible to notice such minor errors on a cursory inspection.

Details: \url{http://www.theregister.co.uk/2014/04/09/heartbleed_explained/}

\paragraph{Shellshock (Bashdoor)}
From 1998 to 2014, it was possible for any user to gain root access in the bash shell on Unix-based systems.
The upgrade cost is unknown but was generally small because updates were rolled out within $1$ week of publication.
Moreover, in certain server applications that passed data to bash this was possible for arbitrary clients as well.

The cause was the use of unvalidated strings to represent complex data.
Bash allowed storing function definitions as environment variables in order to share function definitions across multiple instances.
The content of these environment variables was trusted because function definitions are meant to be side-effect-free.
However, users could append $; C$ to the value of an environment variable defining a function.
When executing this function definition, bash also executed $C$.

%env x='() { :;}; C bash -c :
%means
%x = 'lambda(). : ; C
%and C is also executed (with root privileges)

Independently, many server applications (including the widely used cgi-bin) pass input provided by remote users to bash through environment variables.
This resulted in input provided by remote clients being passed to the bash parser, which was against the assumptions of the parser.
Indeed, several bugs in the bash parser caused remotely exploitable vulnerabilities.

Details: \url{https://fedoramagazine.org/shellshock-how-does-it-actually-work/}

\paragraph{Apple 'goto fail' Bug}
From 2012 to 2014, Apple's iOS SSL/TLS library falsely accepted faulty certificates.
This left most iOS applications susceptible to impersonation or man-in-the-middle attacks.
Because Apple updated the software after detecting the bug, its cost is unclear.

The immediately cause was a falsely-duplicated line of code, which ended the verification of the certificate instead of moving on to the next check.
But a number of insufficiencies in the code and the software engineering process exacerbated the effect of the small bug.

The code was as follows:

\begin{lstlisting}
static OSStatus SSLVerifySignedServerKeyExchange(
  SSLContext *ctx, bool isRsa, SSLBuffer signedParams,
  uint8_t *signature, UInt16 signatureLen)
{
	OSStatus        err;
	...

	if ((err = SSLHashSHA1.update(&hashCtx, &serverRandom)) != 0)
		goto fail;
	if ((err = SSLHashSHA1.update(&hashCtx, &signedParams)) != 0)
		goto fail;
		goto fail;
	if ((err = SSLHashSHA1.final(&hashCtx, &hashOut)) != 0)
		goto fail;
	...

fail:
	SSLFreeBuffer(&signedHashes);
	SSLFreeBuffer(&hashCtx);
	return err;
\end{lstlisting}

In a better programming language that emphasizes the use of high-level data structures, the bug would likely not have happened or be caught easily.
But even using C, it could have been caught by a variety of measures including unreachable code analysis, indentation style analysis, code coverage analysis, unit testing, or coding styles that enforce braces around one-command blocks.
 
Details: \url{https://www.imperialviolet.org/2014/02/22/applebug.html}

% see also https://www.dwheeler.com/essays/learning-from-disaster.html for heartbleed, shellshock, and goto fail

\section{Major Failures Caused By System Updates}

\paragraph{Odyssey Court Software}
In an ongoing crisis since 2016, US county court and California and other states have difficulties using the new Odyssey software for recording and dissemination of court decisions.
This has caused dozens of human rights violations due to erroneous arrests or imprisonment.
This includes cases where people spent 20 days in jail based on warrants that had already been dismissed.

The cause is a tight staffing situation combined with the switch to a new, more modern software system for recording court decisions.
The new software expects uses more high-level data types (e.g., reference to a law instead of string) in many places.
This has led to the erroneous recording of decisions and a backlog of converting old decisions into the new database (including decisions that invalidate decisions that are already in the database).

Details: \url{https://arstechnica.com/tech-policy/2016/12/court-software-glitches-result-in-erroneous-arrests-defense-lawyers-say/}

\paragraph{Other Notable Cases}
This is a selection of failures that did not cause direct damage but led to availability failures on important infrastructure.

In 1990, all AT\&T phone switching centers shut down for 9 hours due to a bug in a software update.
An estimated 75 million phone calls were missed.

In 1999, a faulty software update in the British passport office delayed procedures.
About half a million passports were issued late.

In 2004, the UK's child support agency EDS introduced a software update while restructuring the personnel.
This led to several million people receiving too much or too little money and hundreds of thousands of back-logged cases.

In 2015, the New York Stock Exchange had to pause for $3$ hours for a reboot after a software problem.
700,000 trades had to be canceled.

In 2015, hundreds of flights in the North Eastern US had to be canceled or delayed for several hours.
The cause was a problem with new and behind-schedule computer system installed in air traffic control centers.
% http://www.bbc.com/news/world-us-canada-33950381

\section{Other Interesting Failures}

\paragraph{FBI Virtual Case File Project}
In 2005 the Virtual Case File project of the FBI, which had been developed since 2000, was scrapped.
The software was never deployed, but the project resulted in the loss of \$$170$ million of development cost

The cause was systemic failures in the software engineering process including
\begin{compactitem}
 \item poor specification, which caused bad design decisions
 \item repeated specification changes
 \item repeated change in management
 \item micromanagement of software developers
 \item inclusion of many personnel which little training in computer science in key positions
\end{compactitem}
These problems were exacerbated by the planned flash deployment instead of a gradual phasing-in of the new system---a decision that does have advantages but made the systems difficult to test and made it easier for design flaws to creep in.
The above had two negative effects on the code base
\begin{compactitem}
 \item increasing code size due to changing specifications
 \item increasing scope due to continually added features
\end{compactitem}
which exacerbated the management and programming problems.

\paragraph{Excel Gene Names}
In 2016, researchers found that about 20\% of papers in genomics journals contain errors in supplementary spreadsheets.

The cause is that Microsoft Excel by default guesses the type of cell data that is entered as a string and converts the string into that type.
This affects gene names like "SEPT2" (Septin 2, converted to the date September 02) or REKIN identifiers like "2310009E13" (converted to the floating point number $2.31E+13$).

Details: \url{https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-1044-7}

\paragraph{Failures in Involving Computer-Related Manufacturing}
This is a selection of other notable failures that involve hardware manufacturing.

In 2006, two Airbus plants used incompatible version of CAD software.
This resulted in cables being produced too short to connect.

In 2006, Sony batteries mostly used in Dell notebooks had to be recalled.
The resulting cost was about \$$100$ million.

In 2016, Samsung Galaxy phones had to be recalled due to faulty batteries.

\section{Major Vulnerabilities due to Weak Security}

\subsection{Software and Internet}

\paragraph{Operating Systems}
Vulnerabilities in operating systems are critical because only a few systems are used worldwide so that any problem is shared by many users.
Moreover, the operating system usually has full access to the computer and its network, which allows any attack to do great damage.

Moreover, operating systems are usually bundled with standard applications (e.g., web browser, email viewer).
These are tightly integrated with the OS (e.g., by using the same libraries for encryption or accessing files).
Thus, a vulnerability often badly affects the majority of users who use these standard applications.

In 2000, the ILOVEYOU worm used weaknesses in the Windows and Outlook to infect a significant share of all internet-connected computers within a few days.
Its damage was estimated at over \$$5$ billion and the removal costs at over \$$410$ billion.

In recent years operating system companies have reacted to these problems.
They have become more sensitive to security issues and allow for coordinated disclosure of vulnerabilities together with swift updates.
Most noticably for end users, they more and more nudge or even force users to install updates.
For example,
\begin{compactitem}
\item Microsoft Windows 10 automatically downloads and installs updates in a way that users cannot prevent.
\item Google's Android now reserves the right to download minor updates immediately, even via mobile data.
\end{compactitem}
This has greatly reduced the frequency of major problems.

An additional problem is that attacks are often conducted by state governments for purposes of terrorism, oppresion, espionage, sabotage, or law enforcement.

In 2010, the stuxnet worm was used by presumably the US and/or Israel to sabotage Iran's nuclear program.
It was the most sophisticated attack to become public, involving multiple zero-day exploits and including attacks on programmable logic controllers.

In 2013, Edward Snowden revealed a massive secret surveillance program run by the US government.
It used many ways to intercept data sent by users either at transmission nodes or at company data centers.
This included connection metadata and any unencrypted or decryptable content.
The stolen data remains mostly secret so that it remains unclear what was compromised and how it was used.
In response, many software companies introduced end-to-end encryption that precludes even themselves to access their users data.

In 2016, Citizen Lab discovered an attack that used previously unknown vulnerabilities in Apple's Safari on iOS.
It allowed, for the first time, an attacker to remotely take full control of the iPhone, triggered as soon as Safari was pointed to the attack URL.
It is suspected that the exploit was produced commercially by the Israeli company NSO Group and used (at least) by the United Arab Emirates to spy on dissidents.

Details: \url{http://www.vanityfair.com/news/2016/11/how-bill-marczak-spyware-can-control-the-iphone}

\paragraph{Cloud Services}
Consumers are more and more using internet services for their processing needs.
These include
\begin{compactitem}
\item file storage, e.g., via Dropbox
\item email and calendar services, e.g., via gmail
\item office applications, e.g., directly via Google's office web site or indirectly via Microsoft's office suite
\item social networking, e.g., via Facebook
\end{compactitem}
Most modern operating systems and their bundled applications store large amounts of user data on the company's web servers, including, e.g., message archive, photographs, or location history.
This creates unprecented risks for privacy with legal regulation mostly lagging behind.
(Most legislation was designed to limit the government from violating privacy.
Corporations were barely restricted they used to have less power.)

Because most users do not understand the technical issues, accept terms of service blindly, and grant access rights to applications generously, more and more user data is available to the free market.
This is used for both legitimate (e.g., advertising-financed free services) or questionable purposes (e.g., manipulating voter preferences through personalized messages).

In 2014, The Fappening was an attack that combined phishing and password-guessing to gain access to many user accounts on Apple's iCloud.
These acounts included, among other things, backups of all photographs taken with iPhones.
Among the private data stolen and published were hundreds of nude pictures of celebrities.

\paragraph{Large Institutions}
In 2014, Sony Pictures suffered a major break in (possibly by North Korea to blackmail or punish Sony in relation to the movie \emph{The Interview}) mostly facilitated by unprecedented negligence.
Problems included
\begin{compactitem}
 \item unencrypted storage of sensitive information
 \item password stored in plain text files (sometimes even called ``passwords'' or placed in the same directory as encrypted files)
 \item easily guessable passwords
 \item large number of unmonitored devices
 \item lack of accountability and responsibility for security, ignorance towards recommendations and audits
 \item lack of systematic lesson-learning from previous failures (which included 2011 hacks of Sony PlayStation Network and Sony Pictures that stole account information including unsalted or plain text passwords)
 \item weak IT and information security teams
\end{compactitem}
Stolen data included employee data (including financial data), internal emails, and movies.

In 2016, the US democratic party's headquarters suffered a breakin (possibly by Russia to manipulate or discredit that year's presidential election).
The stolen data included in particular internal emails and personal data of donors.
Especially, the former hurt the public perception of the party's campaign to an unknown degree that may or may not have been decisive.

\paragraph{Web Site Account Data}
Many organizations holding user data employ insufficient security against digital break-ins and insufficient (if any) encryption of user data.
They get hacked so routinely that a strong market for stolen identities has developed, often pricing bulk datasets at a few dollars per identity.
An overview can be found at \url{https://haveibeenpwned.com/}.

The effects are exacerbated by two effects:
\begin{compactitem}
 \item System administrators are not sufficiently educated about password hashing, often false believing default hash configurations to be secure.
 Thus, hacks often allow inverting the hash function thus exposing passwords in addition to the possibly sensitive user data.
 \item Users are not sufficiently educated about systematically using different passwords on every site.
 Thus, any breach also compromises accounts on any other sites that use the same user name or email address and password.
\end{compactitem}

Many websites now offer and nudge users to use two-factor authentification to protect accounts from identity theft.
A second factor (e.g., via email or text message) may be required for every login, for every login from a new location, or for every sensitive action like changing the password.
Security questions, which are particularly vulnerable, are phased out by leading companies.
But both websites and users are slow to get used to it.
\medskip

The following describes a few high-profile cases.

In a (estimated) 2008 (only reported in 2016) of myspace, about $360$ million accounts were compromised.
The stolen data included user name, email address, and badly hashed passwords (unsalted SHA1).

In a 2012 hack of linkedin, $160$ million accounts were compromised.
The stolen data included user name, email address, and badly hashed passwords (unsalted SHA1).

In a 2015 hack of Ashley Madison, about $30$ accounts were compromised.
The stolen records included name, email address, hashed password, physical description, and sexual preferences.
Most passwords were hashed securely (using bcrypt for salting and stretching), but about $10$ million passwords were hashed insecurely (using a single MD5 application).
This led to multiple extortion attempts and possibly suicides.
% https://nakedsecurity.sophos.com/2015/09/10/11-million-ashley-madison-passwords-cracked-in-10-days/

In a 2016 hack of the Friend Finder network, about $400$ million accounts were compromised.
The stolen records included name, email address, registration date, and unhashed or badly hashed passwords.
% https://www.leakedsource.com

In two separate hacks in 2013 (only reported in 2016) and 2014 of Yahoo, over $1$ billion user accounts were compromised by presumably state-sponsored actors.
The stolen records included name, email address, phone number, date of birth, and hashed passwords, and in some cases security questions and answers.

\subsection{Dedicated Systems}

Many domains are increasingly using computer technology.
Often this is done by engineers with little training in computer science and even less training in security aspects.
In many cases, the resulting systems are highly susceptible to attacks, spared only by the priorities of potential hackers and terrorists.

\paragraph{Embedded Systems}
Embedded systems are increasingly running high-level operating systems, typically variants of Linux or Windows, and software.
They are particularly vulnerable due to a number of systemic flaws:
\begin{compactitem}
\item Software often cannot be updated at all or not conveniently. Thus, they collect many security vulnerabilities over time.
\item Affected devices may be in use for years or decades, thus accumulating many vulnerabities.
\item It is hard or impossible for users to interact with the software in a way that would allow them to understand or patch its vulnerabilities.
\item Access is often not secured or not secured well.
Often master passwords (possibly the same on every instance of the system and possibly hard-coded) are used to allow access for technicians.
\end{compactitem}

\paragraph{Cars}
The upcoming wave of self-driving cars requires the heavy use of experienced software developers and a thorough regulation process.
It is therefore reasonable to hope that security will play a major role in the design and legal regulation.

But even today's traditional cars are susceptible to attacks including remote takeover of locks, wheels, or engine.
The causes are
\begin{compactitem}
 \item not or not properly protected physical interfaces for diagnostics and repair,
 \item permanent internet connections, which are useful for navigation and entertainment, that are not strictly separated from engine controls.
\end{compactitem}
One of the more high-profile benevolent attack demonstrations was described in \url{https://www.wired.com/2015/07/hackers-remotely-kill-jeep-highway/}.

\paragraph{Medical Systems}
Hospitals and manufacturers of medical devices are notoriously easy to hack.

Weaknesses include unchangeable master passwords, unencrypted communication between devices, outdated and non-updateable software running in devices, and outdated or non-existent protection against attackers.
Systemic causes include a highly-regulated release process that precludes fast patching of software and a slow update cycle.

Details:
\url{http://cacm.acm.org/magazines/2015/4/184691-security-challenges-for-medical-devices/fulltext}

See also the Symantec 2016 Healthcare Internet Security Threat Report available at \url{https://www.symantec.com/solutions/healthcare}

%\subsection{Public Processes}
 % digital signatures
 % elections