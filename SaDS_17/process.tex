\section{Process Aspects}This section collects general methods that have been developed by practitioners to get a better handle on managing the software engineering process.They are generally very cheap and easy to deploy.Therefore, it should\footnote{It is not, though.} be considered gross\footnote{\emph{Gross} negligence is the kind that makes people liable to prosecution or litigation.} negligence to develop dependency-critical software without any one of these.However, training lacks behind with many current developers not updated on latest technologies.   \subsection{Coding Style}  There are many aspects of a program that have no semantic relevance.These include\begin{compactitem} \item most whitespace including   \begin{compactitem}    \item indentation and vertical alignment    \item tabs vs. spaces    \item placement of opening and closing brackets    \item optional spaces between operators and arguments   \end{compactitem}  \item choice of names for any names that are not fixed in the specification of the interface    \begin{compactitem}     \item private methods and field of a class     \item local variables of a function     \item classes and similar units that are not part of the specification    \end{compactitem}  \item syntactic restrictions on names including   \begin{compactitem}     \item length of names (documenting effect vs. readability)     \item capitalization of first character (e.g., lower case for values, upper case for types)     \item capitalization of inner characters (e.g., camel case vs. underscores)   \end{compactitem}  \item syntactic restrictions on declarations including   \begin{compactitem}     \item length of a method     \item number of declarations in a class     \item order of declarations (e.g., public vs. private, values vs. methods, mutable vs. immutable)   \end{compactitem}  \item formatting of structured documentation including   \begin{compactitem}     \item placement of documentation inside the comment     \item use of markdown syntax inside comments     \item presence and order of keywords (e.g., author, param, return)   \end{compactitem}   \item placement and formatting of comments containing verification-relevant information including   \begin{compactitem}     \item pre/postconditions of methods     \item class invariants     \item loop invariants     \item termination orderings for loops and recursive functions   \end{compactitem}\end{compactitem}  By standardizing these across a large project, readability is greatly enhanced.This is particularly important when it happens frequently that\begin{compactitem} \item new programmers join a team and have to be quickly retrained on the entire code base \item programmers move between teams \item different teams work on the same code\end{compactitem}Style checkers can be standalone or integrated into an IDE.Either way, they allow customizing a style and enforcing it throughout a project.Modern IDEs (e.g., IntelliJ) provide a wide variety of coding style configurations whose violation results in special warning.  \subsection{Documentation}Thorough documentation is used for multiple purposes:\begin{compactitem} \item tie the implementation to the specification (e.g., by referencing the exact page or item of the specification corresponding to a declaration) \item inform other programmers about functionality and important subtleties \item provide examples for how to instantiate a class or call a function \item automatically extract web pages containing API documentation \item attach verification-relevant information that can be automatically extracted by verifiers\end{compactitem}Most programming languages come with supporting tools that allow for structured documentation. For example, Javadoc is a structured documentation language for Java.The following example snippet is taken from the Javadoc home page:\begin{lstlisting}/** * Returns an Image object that can then be painted on the screen.  * The url argument must specify an absolute {@link URL}. The name * argument is a specifier that is relative to the url argument.  * <p> * This method always returns immediately, whether or not the  * image exists. When this applet attempts to draw the image on * the screen, the data will be loaded. The graphics primitives  * that draw the image will incrementally paint on the screen.  * * @param  url  an absolute URL giving the base location of the image * @param  name the location of the image, relative to the url argument * @return      the image at the specified URL * @see         Image */ public Image getImage(URL url, String name) {        try {            return getImage(new URL(url, name));        } catch (MalformedURLException e) {            return null;        } }\end{lstlisting}Note how it\begin{compactitem} \item uses \lstinline|/**| instead of the usual \lstinline|/*| to indicate a structured comment \item can link to other code parts (which requires some compilation knowledge to resolve relative references in the documentation) \item integrates HTML which is carried through to the generated web pages \item uses keywords like \lstinline|@param| so that better web pages can be produced \item is connected to the code by repeating the names of the function variables (which can be flagged by the style checker)\end{compactitem}\subsection{Versioning}Sophisticated version management systems like svn and recently git have tremendously improved the development process.Specifically, the use of git for the Linux kernel and the success of github have made a huge impact in the open source community.They allow\begin{compactitem} \item collaboration across physical distances \item maintaining different version of a software (e.g., a release and a development branch) \item retroactively determining when and by whom a bug was introduced \item automated building and testing on every commit\end{compactitem}The following article about google repository management is particularly interesting:\url{http://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext}\subsection{Code Review}Code review is the process of programmers reviewing each other's code before (or sometimes after) it becomes part of the stable parts of the code base.Many modern versioning tools simplify the process by\begin{compactitem} \item reifying changes (e.g., as diffs/patches or commits) so that each change can be reviewed and applied individually \item managing the available changes and applying them to branches \item maintain the proposed changes and the feedbacks and decisions by the reviewer\end{compactitem}Github's maintenance of git pull requests is a simple example of a systematic code review process.\subsection{Automated Building and Testing}Most commit-based software repositories allow for hooks that are executed automatically before or after every commit (called push in git).This is typically used for testing.A typical commit hook should\begin{compactitem} \item create a fresh checkout of the source code \item build the source \item run a test suite (where the test may be part of the source or provided externally)\end{compactitem}For most repository managers, automated build managers exist.They can generate reports for every commit and, e.g., alert users by emails upon new commits that fail the tests.A pre-commit hook can even reject the commit if the test failed.travis is a typical example.It is well-integrated with, e.g., github.\subsection{Issue-Tracking}Issue track is the systematic management of known problems, their discussion, and eventual solution.Usually an issue is maintained as a discussion thread, and all open issues are available in a list that allows for filtering and sorting.They are typically provided via web interfaces, in particular to allow users to easily submit issues.The typical process is\begin{compactenum} \item The initial post \textbf{opens} the issue. \item After some discussion, the issue is \textbf{assigned} to a programmer or team. \item After posting and checking the solution, the issue is \textbf{closed}.\end{compactenum}There is a wide variety of issue tracking systems, usually independent of the programming language.Many are integrated with wikis or versioned repositories.Examples are trac and github.\section{Programming Aspects}This section collects mostly independent practices for individual aspects of programming.\subsection{Input Validation and Internal Syntax}The following is a fundamental principle that is absolutely necessary when handling user input:\begin{compactitem} \item There is a data structure that represents the input/external syntax. This data structure is called the internal syntax. It should exactly follow the grammar of the input language.\footnote{Incidentally, this means that untyped languages are out} \item All processing proceeds in the following steps: \begin{enumerate} \item User input is parsed from a string holding external syntax into an object of type of the internal syntax.  The parser must be side-effect-free: It does not nothing but parse and return an object of the internal syntax or an error message.  Failure results in immediately rejecting the user input.  \item All processing that ever happens works with the internal syntax.  External syntax is never visible to any other function than the parser.  \item The data structure provides a printer (also called serializer) that turns it into a string.  Any output that is to be displayed to the user is generated in this way. \end{enumerate}\end{compactitem}It is desirable that parser and printer are exactly inverse to each other.However, it is common that certain aspects of the internal syntax are lost after parsing and printing (e.g., whitespace).However, no meaningful information should be lost, e.g., the parser should not insert default value for omitted optional arguments---instead, it must record that the argument was omitted.Conversely, parsing followed by printing must succeed and must result in the original object.Thus, we must have $parse(print(i))=i$ and ideally also $print(parse(e))=e$. \subsection{Common Bugs}We know that correctness is undecidable.But that is irrelevant for a pragmatic approach: the more can be avoided, the better.Due to undecidability, detecting bugs requires insight and careful case-by-case analyis, which is expensive.Therefore, it has become very successful to focus on one kind of bug and then to systematically find its occurrences.This will usually guarantee bug-freeness but can be very to guard against common bugs.We can think of these as individual heuristics, each hunting for a specific common bug.Often these heuristics are integrated with the compiler and/or the IDE and can be used to report warnings.\paragraph{Array and List Bounds}When iterating over an array or a list, we often use for-loops with an integer variable that runs from $0$ to $n-1$, where $n$ is the length.Often the length is statically (i.e., at compile-time, without executing) known.For example, if an array is created via $x=Array[\Int](n)$, we expect for-loop that read or write to $x$ to run from $0$ to $n-1$.If the bounds are different, that can be used to generate a warning.This is only a heuristic, of course.For the general case, we have to prove that the index $i$ in $x[i]$ is between $0$ and $n-1$.There are tools that indeed try to prove that.\medskipAn even better solution is to avoid loops altogether that only count up index variables.Instead, we can use $map$ or $foreach$ operations that traverse an array.For example, to shift all values in $x$ one up, we can use a counter with subtle traps \begin{acode}\afor{i}{1}{x.length-1}{ x[i-1]:=x[i]}\\x[x.length-1]:=0\end{acode}A better solution is to use language constructs that enforce the correctness: traversal operators on traversable data structures:\begin{acode}x.indices.tail\;foreach\;i =>\ablock{ x[i-1]:=x[i]}\\x[-1]:=0\end{acode}Here our knowledge about the methods $indices$ and $tail$ guarantee that the assingment is only executed for indices of elements that have an element before them---no fiddling with the bounds of the for-loop is needed.Moreover, the last assignment uses modular arithmetic to access the last element without fiddling with the length.\paragraph{Buffer Bounds}Buffers can be treated as special arrays.The same techniques apply.A particularly insane (and useless) property of buffers in certain low level programming languages is that the length of the buffer can be fixed in memory but not fixed in the programming language.Thus, after creating a buffer of size $n$, we can overread from it, i.e., read $m>n$ values from it.In this case, a C-like language will happily read whatever resides in memory after the buffer.That can easily be avoided by\begin{compactitem} \item using high-level data structures that hide the memory allocation from users of the data structure, \item or (even better) using high-level programming languages that hide the memory allocation from the programmer entirely.\end{compactitem}In the latter case, buffer overreads are at least run-time exceptions.\paragraph{Null Pointers}Null pointers are routinely used by bad programmers, especially in bad programming languages.Analysis tools can inspect every dereferencing of a pointer $x$ and check if there is a previous assignment that assigns a non-null value to $x$.\medskipA better solution is not to use $null$ in the first place.Indeed, good programmers program as if $null$ does not exist.A better solution is to use language constructs that enforce the correctness: the option type\begin{acode}\adata{Option[A]}{Some(value:A),None}\end{acode}which provides an explicit value for absent values.Now every access to $x:Option[A]$ has to say what to for each of the two possible cases.The only exception is when calling an external library that uses $null$.But even in that case, it is best to use back-and-forth translations between possibly-null and option values:\begin{acode}\afun[{Option[A]}]{fromMaybeNull[A]}{x:A}{  \aifelse{x==null}{None}{Some(x)}}\\\afun[A]{toMaybeNull[A]}{x:Option[A]}{  x.getOrElse(null)}\end{acode}\paragraph{Casting}Analysis tools can inspect every type cast $\aasinst{x}{B}$ of a value $x$ to type $B$.They can infer the type of $x$, say $A$, and check for\begin{compactitem} \item plausibility: is $B$ a subtype of $A$---if not, the cast is definitely a bug, \item correctness: is $x$ guaranteed to have type $B$---that requires a proof.\end{compactitem}Such casts are typically guarded as in\begin{acode}\aifelse{\aisinst{x}{B}}{f(\aasinst{B})}{g(x)}\end{acode}A better solution is to use language constructs that enforce the correctness.One way to do this is a case-distinction operator\begin{acode}\amatch{x}{\acase{x:B}{f(x)}, \acase{\_}{g(x)}}\end{acode}which allows the compiler to spot a missing case if the second case is forgotten.An even simpler solution is to use a cast operator that returns an options value:\begin{acode}\afun[{Option[B]}]{optCast}{x:A}{\ldots}\\(optCast(x)\; map\; f).getOrElse(g(x))\end{acode}\paragraph{Uninitialized Memory}Some programming languages allow introducing names without initial values.Those can be variables or (in C-like low-level languages) memory areas.Uninitialized variables can easily be spotted by analysis tools.They should not be warnings but actual compiler bugs.Allowing them at all is a design flaw of the programming language.A variant uninitialized variables are variables initialized with $null$.That is equally easy to spot and equally forbidden.Uninitialized memory areas are occasionally useful when initializing a large memory area is considered too costly.In most cases, this can be avoided entirely by using good data structures.For example, there is no need to use that is known to be filled later anyway Those may be variables, which are simply declared without value.That\paragraph{Unreachable Code}If no execution can ever execute a certain command, we speack of unreachable code.It is always a bug.Many instances of unreachable code can be detected automatically.This includes\begin{compactitem}  \item code in a branch of an if-else whose condition always has the same value  \item code in a case distinction (switch) statement that come after a default case  \item code after a return statnent\end{compactitem}\subsection{Safe by Design}This section collects a few implementation principles that help minimize the likely hood of errors.\paragraph{Safe Defaults}Default and initial values should always be chosen in such a way that they lead to the minimal possible behavior.For example, a security check should be wrapped in an exception handler that treats every exception as failure of the check.\paragraph{Minimal Interfaces and Access Rights}Any component $C$ that needs access to critical shared component $D$ should have only the minimal access rights needed for its correct operation.For example, a separate abstract class $D'$ can be written that contains only those methods of $D$ that $C$ needs.$C$ should then by implemented against $D'$ rather than $D$.If $D$ is a database, file system, or similar external resource, we should write special functions that wrap around the access to $D$ in exactly the way needed by $C$.For example, if $C$ often has to append to a file, we write a function for appending to a file;$C$ will call only that function to access the file, and no other part of $C$ makes any file system access.\section{Stability}Frequent changes are extremely dangerous to even the best software development process.Stability is particularly important for\begin{compactitem}  \item the specification,  \item the design of the data structures and algorithms,  \item the project team,  \item the coding style,  \item the workflows for building, committing, etc.,  \item the policies for access, review, and approval of changes.\end{compactitem}It is very tempting for managers, marketing department, and customers to request changes because they seem easy to them.Even many programmers often underestimate their dangers.But every change at a high level introduces lots of increasingly greater and more expensive changes at lower levels.Eventually, the lower levels (especially when resources are tight, which is always the case) have to introduce workarounds, hacks, and special-case treatments to handle the changes.To the top-level person who requested the change, everything looks fine because the lower levels will usually do a good job of hiding the mess.But below the surface the codebase will become increasingly messy until it is unmanagable.A good metaphor is to think of a long stick representing the hiearchy.The person at the top points the stick at a slightly different angle, which does not very different from the top.But at the lower end of the stick, the small change in angle caused a massive shift of the end of the stick.The shift may be much bigger than what the inertia of the stick allows, and the sticks breaks somewhere in the middle.When the stick breaks, the people at the breaking point in the middle move the lower half of the stick so that it points to the right point and hire two new people $A$ and $B$.$A$ constantly measures the movement of the upper half of the stick and shouts the values to $B$.$B$ then computes how much the lower half would move if the halves were still connected and moves the lower half accordingly.The person at the top does not notice anything.But over time, the stick has broken into many pieces, and lots of people are in charge of pretending it is still one piece.